# analiseementasstreamlit.py
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import numpy as np
import re
import os
import zipfile
import tempfile
import pdfplumber
from io import BytesIO
from sentence_transformers import SentenceTransformer, util
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap                    # pip install umap-learn
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import openai
import xlsxwriter               # para formata√ß√£o condicional no Excel
from xlsxwriter.utility import xl_rowcol_to_cell

# --------------------------------------------------
# 1) Configura√ß√£o da p√°gina Streamlit
# --------------------------------------------------
st.set_page_config(layout="wide")
st.title("üìÇüìë An√°lise de Ementas via pasta .zip")

# --------------------------------------------------
# 2) Cache de recursos pesados
# --------------------------------------------------
@st.cache_data(show_spinner=False)
def parse_ementas(zip_bytes: bytes) -> pd.DataFrame:
    """Extrai e limpa ementas de um ZIP de PDFs."""
    with tempfile.TemporaryDirectory() as tmpdir:
        z = zipfile.ZipFile(BytesIO(zip_bytes))
        z.extractall(tmpdir)
        regs = []
        for root, _, files in os.walk(tmpdir):
            for fn in files:
                if not fn.lower().endswith(".pdf"):
                    continue
                path = os.path.join(root, fn)
                txt = ""
                with pdfplumber.open(path) as pdf:
                    for p in pdf.pages:
                        txt += (p.extract_text() or "") + "\n"
                # remove rodap√©s tipo "2 de 3"
                txt = re.sub(r"(?m)^\s*\d+\s+de\s+\d+\s*$", "", txt)
                # extrai nome e c√≥digo
                m = re.search(
                    r"UNIDADE CURRICULAR[:\s]*(.+?)\s*\(\s*(\d+)\s*\)",
                    txt, re.IGNORECASE | re.DOTALL
                )
                nome = m.group(1).strip() if m else fn
                cod  = m.group(2).strip() if m else fn
                # extrai conte√∫do program√°tico
                m2 = re.search(
                    r"Conte[√∫u]do program[a√°]tico\s*[:\-‚Äì]?\s*(.*?)(?=\n\s*Bibliografia|\Z)",
                    txt, re.IGNORECASE | re.DOTALL
                )
                conteudo = m2.group(1).strip() if m2 else ""
                regs.append({
                    "COD_EMENTA": cod,
                    "NOME UC": nome,
                    "CONTEUDO_PROGRAMATICO": conteudo
                })
    return pd.DataFrame(regs)

@st.cache_data(show_spinner=False)
def get_embeddings(texts: list[str]) -> np.ndarray:
    """Gera embeddings SBERT em batches (usa o model global)."""
    return model.encode(texts, batch_size=32, convert_to_tensor=False)

@st.cache_data(show_spinner=False)
def name_cluster_with_gpt(prompt: str, api_key: str) -> str:
    """Gera nome de cluster via GPT-3.5 (cache por prompt)."""
    openai.api_key = api_key
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Voc√™ resume grupos de ementas em um nome curto."},
            {"role": "user",   "content": prompt}
        ],
        temperature=0.0,
        max_tokens=20
    )
    return resp.choices[0].message.content.strip().strip('"')

# --------------------------------------------------
# 3) Upload dos arquivos
# --------------------------------------------------
uploaded_zip = st.file_uploader("üì• Fa√ßa upload do ZIP de ementas (PDF)", type="zip")
if not uploaded_zip:
    st.info("Aguardando upload do ZIP...")
    st.stop()

df_ementas = parse_ementas(uploaded_zip.read())
st.success(f"{len(df_ementas)} ementas carregadas.")
st.dataframe(df_ementas.head())

# op√ß√£o de corre√ß√£o de pontua√ß√£o
use_corr = st.sidebar.checkbox("Corrigir pontua√ß√£o com ChatGPT antes de separar frases?")
api_key_corr = ""
if use_corr:
    api_key_corr = st.sidebar.text_input("Chave OpenAI para corre√ß√£o:", type="password")
    if api_key_corr:
        openai.api_key = api_key_corr
        with st.spinner("Corrigindo pontua√ß√£o dos conte√∫dos..."):
            def corrige(txt: str) -> str:
                resp = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role":"system","content":"Voc√™ √© um corretor de pontua√ß√£o de texto."},
                        {"role":"user","content":f"Corrija a pontua√ß√£o deste texto, sem alterar o conte√∫do:\n\n{txt}"}
                    ],
                    temperature=0.0,
                    max_tokens=len(txt.split())+50
                )
                return resp.choices[0].message.content.strip()
            df_ementas["CONTEUDO_PROGRAMATICO"] = df_ementas["CONTEUDO_PROGRAMATICO"] \
                .apply(lambda t: corrige(t) if isinstance(t,str) and t.strip() else t)
    else:
        st.sidebar.warning("Informe a API Key para habilitar corre√ß√£o.")

uploaded_enade = st.file_uploader("üì• Fa√ßa upload do Excel de compet√™ncias ENADE", type="xlsx", key="enade")
if not uploaded_enade:
    st.info("Aguardando upload do Excel ENADE...")
    st.stop()

enade = pd.read_excel(uploaded_enade).dropna(subset=['DESCRI√á√ÉO'])
enade['FRASE_ENADE'] = enade['DESCRI√á√ÉO'].str.replace('\n',' ').str.split(r'[.;]')
enade_expl = (
    enade.explode('FRASE_ENADE')
         .assign(FRASE_ENADE=lambda df: df['FRASE_ENADE'].str.strip())
)
enade_expl = enade_expl[enade_expl['FRASE_ENADE'].str.len() > 5].reset_index(drop=True)

# --------------------------------------------------
# 4) Sele√ß√£o da an√°lise
# --------------------------------------------------
analise = st.sidebar.selectbox("Escolha a An√°lise", [
    "Clusteriza√ß√£o Ementas",
    "Matriz de Similaridade",
    "Matriz de Redund√¢ncia",
    "An√°lise Ementa vs ENADE"
])

# --------------------------------------------------
# 5) Carrega modelo SBERT em cache
# --------------------------------------------------
@st.cache_resource
def load_sbert():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
model = load_sbert()

# ... o resto do c√≥digo permanece inalterado ...
